{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a11cd99-bed1-4487-83e2-2488bda3f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original CSV files...\n",
      "Loading pre-processed image embeddings (this may take a minute)...\n",
      "✅ Embeddings loaded.\n",
      "Merging image features into main dataframes...\n",
      "✅ Data loading and merging complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>price</th>\n",
       "      <th>img_0</th>\n",
       "      <th>img_1</th>\n",
       "      <th>img_2</th>\n",
       "      <th>img_3</th>\n",
       "      <th>img_4</th>\n",
       "      <th>img_5</th>\n",
       "      <th>...</th>\n",
       "      <th>img_2038</th>\n",
       "      <th>img_2039</th>\n",
       "      <th>img_2040</th>\n",
       "      <th>img_2041</th>\n",
       "      <th>img_2042</th>\n",
       "      <th>img_2043</th>\n",
       "      <th>img_2044</th>\n",
       "      <th>img_2045</th>\n",
       "      <th>img_2046</th>\n",
       "      <th>img_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33127</td>\n",
       "      <td>Item Name: La Victoria Green Taco Sauce Mild, ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.065593</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.670622</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.590448</td>\n",
       "      <td>0.741287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205975</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>0.067109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.999065</td>\n",
       "      <td>0.064973</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.710594</td>\n",
       "      <td>0.010265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198967</td>\n",
       "      <td>Item Name: Salerno Cookies, The Original Butte...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.193857</td>\n",
       "      <td>0.358459</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.045958</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.555398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142510</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.120086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282566</td>\n",
       "      <td>0.187292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261251</td>\n",
       "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.071409</td>\n",
       "      <td>0.745915</td>\n",
       "      <td>1.709077</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>0.154619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201331</td>\n",
       "      <td>0.496778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145555</td>\n",
       "      <td>0.918642</td>\n",
       "      <td>0.553077</td>\n",
       "      <td>0.122053</td>\n",
       "      <td>0.384103</td>\n",
       "      <td>0.470413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55858</td>\n",
       "      <td>Item Name: Judee’s Blue Cheese Powder 11.25 oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "      <td>30.34</td>\n",
       "      <td>0.212073</td>\n",
       "      <td>0.238302</td>\n",
       "      <td>0.310819</td>\n",
       "      <td>0.335903</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134894</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.119571</td>\n",
       "      <td>0.995192</td>\n",
       "      <td>0.697332</td>\n",
       "      <td>0.142514</td>\n",
       "      <td>0.492120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292686</td>\n",
       "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Oun...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "      <td>66.49</td>\n",
       "      <td>0.071024</td>\n",
       "      <td>0.115265</td>\n",
       "      <td>0.602926</td>\n",
       "      <td>0.309518</td>\n",
       "      <td>0.022051</td>\n",
       "      <td>0.131149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192766</td>\n",
       "      <td>0.937161</td>\n",
       "      <td>0.020276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095623</td>\n",
       "      <td>0.040726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
       "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
       "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
       "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
       "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
       "\n",
       "                                          image_link  price     img_0  \\\n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  0.065593   \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  0.193857   \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  0.071409   \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  0.212073   \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  0.071024   \n",
       "\n",
       "      img_1     img_2     img_3     img_4     img_5  ...  img_2038  img_2039  \\\n",
       "0  0.011724  0.670622  0.025974  0.590448  0.741287  ...  0.205975  0.018378   \n",
       "1  0.358459  0.001256  0.045958  0.005887  0.555398  ...  0.142510  0.017008   \n",
       "2  0.745915  1.709077  0.008416  0.005543  0.154619  ...  0.201331  0.496778   \n",
       "3  0.238302  0.310819  0.335903  0.004677  0.026607  ...  0.001492  0.000000   \n",
       "4  0.115265  0.602926  0.309518  0.022051  0.131149  ...  0.000000  0.000000   \n",
       "\n",
       "   img_2040  img_2041  img_2042  img_2043  img_2044  img_2045  img_2046  \\\n",
       "0  0.067109  0.000000  0.014577  0.999065  0.064973  0.027026  0.710594   \n",
       "1  0.120086  0.000000  0.017559  0.000000  0.493542  0.000000  0.282566   \n",
       "2  0.000000  0.000000  0.145555  0.918642  0.553077  0.122053  0.384103   \n",
       "3  0.134894  0.021352  0.019757  0.119571  0.995192  0.697332  0.142514   \n",
       "4  0.003945  0.000000  0.192766  0.937161  0.020276  0.000000  0.095623   \n",
       "\n",
       "   img_2047  \n",
       "0  0.010265  \n",
       "1  0.187292  \n",
       "2  0.470413  \n",
       "3  0.492120  \n",
       "4  0.040726  \n",
       "\n",
       "[5 rows x 2052 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"Loading original CSV files...\")\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# --- Load the saved image embeddings ---\n",
    "print(\"Loading pre-processed image embeddings (this may take a minute)...\")\n",
    "with open('../data/train_image_embeddings_FULL.pkl', 'rb') as f:\n",
    "    train_embeddings = pickle.load(f)\n",
    "with open('../data/test_image_embeddings_FULL.pkl', 'rb') as f:\n",
    "    test_embeddings = pickle.load(f)\n",
    "print(\"✅ Embeddings loaded.\")\n",
    "\n",
    "# --- Convert embeddings to DataFrame format ---\n",
    "IMAGE_FEATURE_COUNT = 2048 # ResNet50 gives 2048 features\n",
    "img_cols = [f'img_{i}' for i in range(IMAGE_FEATURE_COUNT)]\n",
    "\n",
    "train_img_df = pd.DataFrame.from_dict(train_embeddings, orient='index', columns=img_cols)\n",
    "train_img_df.index.name = 'sample_id'\n",
    "\n",
    "test_img_df = pd.DataFrame.from_dict(test_embeddings, orient='index', columns=img_cols)\n",
    "test_img_df.index.name = 'sample_id'\n",
    "\n",
    "# --- Merge image features with the main data ---\n",
    "# We use a 'left' merge to keep all original rows\n",
    "print(\"Merging image features into main dataframes...\")\n",
    "train_df_full = train_df.merge(train_img_df, on='sample_id', how='left')\n",
    "test_df_full = test_df.merge(test_img_df, on='sample_id', how='left')\n",
    "\n",
    "# Fill missing image features with 0 (for any images that failed to process)\n",
    "train_df_full[img_cols] = train_df_full[img_cols].fillna(0)\n",
    "test_df_full[img_cols] = test_df_full[img_cols].fillna(0)\n",
    "\n",
    "print(\"✅ Data loading and merging complete.\")\n",
    "display(train_df_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4650e13f-75fa-4096-a069-ee9d788162ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting IPQ features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Local\\Temp\\ipykernel_8312\\1881720353.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_full['ipq'] = train_df_full['catalog_content'].apply(extract_ipq)\n",
      "C:\\Users\\manis\\AppData\\Local\\Temp\\ipykernel_8312\\1881720353.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_full['ipq'] = test_df_full['catalog_content'].apply(extract_ipq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Brand features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Local\\Temp\\ipykernel_8312\\1881720353.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_full['brand'] = train_df_full['catalog_content'].apply(extract_brand)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature engineering complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Local\\Temp\\ipykernel_8312\\1881720353.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_full['brand'] = test_df_full['catalog_content'].apply(extract_brand)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# --- Extract Item Pack Quantity (IPQ) ---\n",
    "def extract_ipq(text):\n",
    "    if not isinstance(text, str): return 1.0\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*(?:oz|ounce|count|pk|pack|fl oz|ct)', text, re.IGNORECASE)\n",
    "    if match: return float(match.group(1))\n",
    "    return 1.0\n",
    "\n",
    "print(\"Extracting IPQ features...\")\n",
    "train_df_full['ipq'] = train_df_full['catalog_content'].apply(extract_ipq)\n",
    "test_df_full['ipq'] = test_df_full['catalog_content'].apply(extract_ipq)\n",
    "\n",
    "# --- Extract Brand ---\n",
    "def extract_brand(text):\n",
    "    if not isinstance(text, str) or len(text) == 0: return \"unknown\"\n",
    "    return text.split()[0].lower()\n",
    "\n",
    "print(\"Extracting Brand features...\")\n",
    "train_df_full['brand'] = train_df_full['catalog_content'].apply(extract_brand)\n",
    "test_df_full['brand'] = test_df_full['catalog_content'].apply(extract_brand)\n",
    "train_df_full['brand'] = train_df_full['brand'].astype('category')\n",
    "test_df_full['brand'] = test_df_full['brand'].astype('category')\n",
    "\n",
    "print(\"✅ Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ca6bda-b16b-412e-abe0-3c4a6dc2bf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing full dataset for training...\n",
      "🚀 Training the final model (Text + IPQ + Brand + Images)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 9.067526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1173461\n",
      "[LightGBM] [Info] Number of data points in the train set: 63750, number of used features: 19773\n",
      "[LightGBM] [Info] Start training from score 2.740886\n",
      "📈 Evaluating final model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\OneDrive\\Desktop\\amazon-price-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "✅ FINAL MODEL VALIDATION SMAPE: 53.0882%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- 1. Define All Feature Types ---\n",
    "text_feature = 'catalog_content'\n",
    "numeric_features = ['ipq']\n",
    "categorical_features = ['brand']\n",
    "image_features = [f'img_{i}' for i in range(IMAGE_FEATURE_COUNT)]\n",
    "\n",
    "# --- 2. Create the Final Preprocessor ---\n",
    "# We use PCA to reduce the 2048 image features to 128\n",
    "# This is faster and often prevents overfitting\n",
    "preprocessor_v4 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(stop_words='english', max_features=20000, ngram_range=(1,2)), text_feature),\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_features),\n",
    "        ('img', PCA(n_components=128, random_state=42), image_features)\n",
    "    ],\n",
    "    remainder='drop' # Drop any columns we didn't specify\n",
    ")\n",
    "\n",
    "# --- 3. Create the Final Model Pipeline ---\n",
    "model_final = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_v4),\n",
    "    ('lgbm', lgb.LGBMRegressor(random_state=42, n_estimators=500, learning_rate=0.05, num_leaves=40))\n",
    "])\n",
    "\n",
    "# --- 4. Define SMAPE (for validation) ---\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    denominator[denominator == 0] = 1e-6 \n",
    "    return np.mean(numerator / denominator) * 100\n",
    "\n",
    "# --- 5. Train and Evaluate on the FULL Dataset ---\n",
    "print(\"Preparing full dataset for training...\")\n",
    "X = train_df_full\n",
    "y_log = np.log1p(X['price'])\n",
    "\n",
    "# Split data for validation\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(X, y_log, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"🚀 Training the final model (Text + IPQ + Brand + Images)...\")\n",
    "model_final.fit(X_train, y_train_log)\n",
    "\n",
    "print(\"📈 Evaluating final model...\")\n",
    "preds_log = model_final.predict(X_val)\n",
    "preds = np.expm1(preds_log)\n",
    "y_val_true = np.expm1(y_val_log)\n",
    "preds[preds < 0] = 0\n",
    "\n",
    "validation_smape = smape(y_val_true, preds)\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"✅ FINAL MODEL VALIDATION SMAPE: {validation_smape:.4f}%\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e664b87-b6ef-47f9-971c-34864e3513fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Training final model on ALL 75,000 samples...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.748103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1305550\n",
      "[LightGBM] [Info] Number of data points in the train set: 75000, number of used features: 19886\n",
      "[LightGBM] [Info] Start training from score 2.739217\n",
      "📝 Generating final predictions on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\OneDrive\\Desktop\\amazon-price-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final submission file created at: ../outputs/submission_final_images.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100179</td>\n",
       "      <td>15.662521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>245611</td>\n",
       "      <td>15.844833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146263</td>\n",
       "      <td>19.810901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95658</td>\n",
       "      <td>12.144444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36806</td>\n",
       "      <td>21.691201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id      price\n",
       "0     100179  15.662521\n",
       "1     245611  15.844833\n",
       "2     146263  19.810901\n",
       "3      95658  12.144444\n",
       "4      36806  21.691201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"🚀 Training final model on ALL 75,000 samples...\")\n",
    "# Train the model on the full 75k sample set\n",
    "model_final.fit(X, y_log)\n",
    "\n",
    "print(\"📝 Generating final predictions on the test set...\")\n",
    "# Use the trained model to predict on the full test set\n",
    "final_predictions = np.expm1(model_final.predict(test_df_full))\n",
    "final_predictions[final_predictions < 0] = 0\n",
    "\n",
    "# --- Create submission file ---\n",
    "submission_final = pd.DataFrame({\n",
    "    'sample_id': test_df_full['sample_id'],\n",
    "    'price': final_predictions\n",
    "})\n",
    "\n",
    "output_path_final = '../outputs/submission_final_images.csv'\n",
    "submission_final.to_csv(output_path_final, index=False)\n",
    "\n",
    "print(f\"\\n✅ Final submission file created at: {output_path_final}\")\n",
    "display(submission_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ba7bd-7f27-4fda-8950-684147d1566a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
