{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e35c024-5a46-4b91-aad4-19a7010f3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the ResNet50 model from local file...\n",
      "✅ ResNet50 model loaded.\n",
      "--- Processing 15000 Training Images ---\n",
      "Downloading training images...\n",
      "Starting sequential download of 15000 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15000/15000 [00:11<00:00, 1361.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image download process complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Train Images: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 15000/15000 [1:16:27<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 15000 train embeddings.\n",
      "\n",
      "--- Processing 15000 Test Images ---\n",
      "Downloading test images...\n",
      "Starting sequential download of 15000 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15000/15000 [1:01:50<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image download process complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Test Images: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 15000/15000 [51:35<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 14999 test embeddings.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "SAMPLE_SIZE = 15000  # We will process 15k train and 15k test images\n",
    "IMAGE_DIR = '../data/images/'\n",
    "\n",
    "# --- Make sure everything is loaded correctly ---\n",
    "# Add src folder to path to find utils.py\n",
    "sys.path.append('../src')\n",
    "from utils import download_images\n",
    "\n",
    "# This line MUST come before the tensorflow import to prevent hanging\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "print(\"Loading the ResNet50 model from local file...\")\n",
    "weights_path = '../data/models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "model = ResNet50(weights=weights_path, include_top=False, pooling='avg')\n",
    "print(\"✅ ResNet50 model loaded.\")\n",
    "\n",
    "# --- Re-using your reliable image processing function ---\n",
    "def get_image_embedding(image_path, model):\n",
    "    try:\n",
    "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        img_preprocessed = tf.keras.applications.resnet50.preprocess_input(img_batch)\n",
    "        embedding = model.predict(img_preprocessed, verbose=0) # verbose=0 keeps output clean\n",
    "        return embedding[0]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ===================================================================\n",
    "#                       PROCESS TRAINING IMAGES\n",
    "# ===================================================================\n",
    "print(f\"--- Processing {SAMPLE_SIZE} Training Images ---\")\n",
    "train_df = pd.read_csv('../data/train.csv').head(SAMPLE_SIZE)\n",
    "train_ids = train_df['sample_id'].tolist()\n",
    "train_links = train_df['image_link'].tolist()\n",
    "train_images_to_download = list(zip(train_links, train_ids))\n",
    "\n",
    "print(\"Downloading training images...\")\n",
    "download_images(train_images_to_download, IMAGE_DIR)\n",
    "\n",
    "train_embeddings = {}\n",
    "output_path_train = f'../data/train_image_embeddings_{SAMPLE_SIZE}.pkl'\n",
    "for sample_id in tqdm(train_ids, desc=\"Processing Train Images\"):\n",
    "    image_path = os.path.join(IMAGE_DIR, f'{sample_id}.jpg')\n",
    "    if os.path.exists(image_path):\n",
    "        embedding = get_image_embedding(image_path, model)\n",
    "        if embedding is not None:\n",
    "            train_embeddings[sample_id] = embedding\n",
    "\n",
    "with open(output_path_train, 'wb') as f:\n",
    "    pickle.dump(train_embeddings, f)\n",
    "print(f\"✅ Saved {len(train_embeddings)} train embeddings.\")\n",
    "\n",
    "# ===================================================================\n",
    "#                         PROCESS TEST IMAGES\n",
    "# ===================================================================\n",
    "print(f\"\\n--- Processing {SAMPLE_SIZE} Test Images ---\")\n",
    "test_df = pd.read_csv('../data/test.csv').head(SAMPLE_SIZE)\n",
    "test_ids = test_df['sample_id'].tolist()\n",
    "test_links = test_df['image_link'].tolist()\n",
    "test_images_to_download = list(zip(test_links, test_ids))\n",
    "\n",
    "print(\"Downloading test images...\")\n",
    "download_images(test_images_to_download, IMAGE_DIR)\n",
    "\n",
    "test_embeddings = {}\n",
    "output_path_test = f'../data/test_image_embeddings_{SAMPLE_SIZE}.pkl'\n",
    "for sample_id in tqdm(test_ids, desc=\"Processing Test Images\"):\n",
    "    image_path = os.path.join(IMAGE_DIR, f'{sample_id}.jpg')\n",
    "    if os.path.exists(image_path):\n",
    "        embedding = get_image_embedding(image_path, model)\n",
    "        if embedding is not None:\n",
    "            test_embeddings[sample_id] = embedding\n",
    "\n",
    "with open(output_path_test, 'wb') as f:\n",
    "    pickle.dump(test_embeddings, f)\n",
    "print(f\"✅ Saved {len(test_embeddings)} test embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f60d00-3ed9-4800-a7d0-239448d6d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
